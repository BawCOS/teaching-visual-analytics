[
["index.html", "Lesson Modules for Teaching Visual Analytics Preface", " Lesson Modules for Teaching Visual Analytics Bradley Warner David Ebert 2018-04-05 Preface http://socviz.co/lookatdata.html http://serialmentor.com/dataviz/ "],
["who-is-this-book-for.html", "0.1 Who is this book for?", " 0.1 Who is this book for? "],
["book-structure-and-how-to-use-it.html", "0.2 Book Structure and How to Use It", " 0.2 Book Structure and How to Use It Introduction: This is a work is the result of an effort between the VACCINE lab at Purdue University and the United States Air Force Academy to develop a smaller set of lesson to introduce the field of visual analytics (VA). Since many institutions do not have the resources to offer complete courses on VA, it was decided that standalone lessons plans have the potential for more use and dissemination. Intent: These modules are designed to help participants: Understand the definition and value of visual analytics Explain and use design principles for visual analytics Use visual analytics to explore and reach a decision for a problem Use: The first chapter is a short introduction to visual analytics. It starts with a question, which can be understood to be the analytic reasoning leg of the visual analytics cycle. The second chapter is also an introduction to visual analytics but it takes more of a hypothesis generating point of view and thus has more emphasis on visualization and interaction. The third chapter is an in-depth chapters give in-depth lessons into each of the three knowledge areas, analytic reasoning, visualization, and interaction. "],
["prerequisites.html", "0.3 Prerequisites", " 0.3 Prerequisites WHY USE R what if you don’t want to These notes make use of the following packages in R knitr (Xie 2017b), rmarkdown (Allaire et al. 2017), fastR (Pruim 2017), Hmisc (Harrell 2018), lattice (Sarkar 2017), vcd (Meyer, Zeileis, and Hornik 2017), ggplot2 (Wickham and Chang 2016), MASS (Ripley 2017), TeachingDemos (Snow 2016), Stat2Data (Lock 2013), car (Fox and Weisberg 2017), DT (Xie 2016),crosstalk (Cheng 2016), leaflet (Cheng, Karambelkar, and Xie 2017), plotly (Sievert et al. 2017), ggrepel(Slowikowski 2017), rpivotTable(Martoglio 2017), RColorBrewer(Neuwirth 2014), gapminder(Bryan 2017), tidyverse(Wickham 2017), readxl(Wickham and Bryan 2017). References "],
["acknowledgements.html", "0.4 Acknowledgements", " 0.4 Acknowledgements The workshop, GT, UCGA, Purdue, USAFA …. This book was written using the excellent bookdown package (Xie 2017a). This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. References "],
["Chpt1.html", "Chapter 1 Introducing Visual Analytics - Emphasis on Analytic Reasoning", " Chapter 1 Introducing Visual Analytics - Emphasis on Analytic Reasoning “The purpose of computing is insight, not numbers.” – Richard Hamming “The simple graph has brought more information to the data analyst’s mind than any other device.” — John Tukey This chapter is an introduction to visual analytics. It starts with a question, which can be understood to be the analytic reasoning leg of the visual analytics cycle. The second chapter is also an introduction to visual analytics but it takes more of a hypothesis generating point of view and thus has more emphasis on visualization and interaction. The depth that you as the instructor use depends on how much time can be devoted to this lesson. This lesson could be done in a little as 30 minutes or as much as three 50 minute lessons. These notes are broken into sections. Under each section are some combination of definitions, explanations, discussion ideas, and problems as needed. You can drop portions or entire sections as needed or dictated by time. Many of the ideas for this chapter come from friendly’s excellent book on the analysis of discrete data (Friendly and Meyer 2016). References "],
["lesson-preparation.html", "1.1 Lesson Preparation", " 1.1 Lesson Preparation 1.1.1 Objectives After the training, participants will: be able to define and explain visual analytics be able to describe the three important components of visual analytics be able to discuss types of unique insights that visual analytics can provide 1.1.2 Preparation Prior to class: Watch the Beauty of Data Visualization - David McCandless Watch TEDxWaterloo - Miriah Meyer - Information Visualization for Scientific Discovery Read the article Visual Analytics: Definition, Process, and Challenges by Daniel Keim, Gennady Andrienko, Jean-Daniel Fekete, Carsten Gorg,Jorn Kohlhammer, and Guy Melan "],
["Intro1.html", "1.2 Lesson Introduction", " 1.2 Lesson Introduction Suggestions to start the lesson: Have the participants discuss the videos and explain insights gained for the preparation work. One of the objectives is to define and explain visual analytics. A useful definition is (this can be given or developed by asking students for input): Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces. Discussion ideas and points for this portion of the lesson include: The goal of visual analytics is to create software systems that will support the analytical reasoning process. Visual analytics can be broken down into a form of analytical reasoning that relies on visual displays that are interactive. We must in turn explore and understand analytical reasoning, visual representation of data, and interactive interfaces. This is a lead into the rest of this lesson. Below is a diagram of the visual analytics process. It is a cycle where any one particular step can be a starting point, and ending point, and a transition point to another area of the cycle. For this lesson we will assume you start with a hypothesis and thus start with analytical reasoning. It is important to note that this is not always the case. You could start with data visualization in an exploratory manner and then move to either analytic reasoning or data visualization. Figure 1.1: Visual Analytics Cycle "],
["AR1.html", "1.3 Analytic Reasoning", " 1.3 Analytic Reasoning This section introduces the concept of analytic reasoning and then uses an example to illustrate the ideas. 1.3.1 Analytic Reasoing Explained The goal of analysis is to make a decision about a question. This question can be part of a larger analysis problem with many questions. Analytic reasoning requires reasoning logically with the support of numeric evidence. The analyst must understand the limitations of the data and the assumptions of the data transformations and summaries. Again it is important to note that analytics reasoning works in conjunction, not separate from, visualization and interaction. In other words, visual analytics takes analytical reasoning further by taking advantages of a visual and interactive representation of data to aid in the creation of knowledge products or actions. Many analytical tasks follow a process of • Information gathering • Re-representation of the information in a form that aids analysis • Development of insight through the manipulation of this representation • Creation of some knowledge product or direct action based on the knowledge insight. 1.3.2 Example We will introduce an example to highlight the ideas and principles of analytic reasoning. The example we selected is easy to understand and allows us to present some of the important concepts of visual analytics. You can pick an example of your own, but remember to keep it simple and easy to understand. 1.3.2.1 Problem: Often in baseball, teams and fans want to compare players. In the 1990s two extraordinary players were Derek Jeter of the New York Yankees and David Justice of the Atlanta Braves. 1.3.2.2 Question: Who was the better baseball player? Take some time and discuss how to answer the question. 1.3.2.3 Discussion ideas: There are many ways to try to answer this question. Someone might say that Jeter was paid more therefore he is better. Or someone would say that the Yankees are a better team and thus Jeter is better. This is known as butterfly reasoning. Typically students will not use an analytic reasoning process but more of an intuition or perhaps just a bias. We have forced the students into an intuitive answer which will likely be based on biases and not empirical evidence. Next we will guide the students further along the path of analytic reasoning by narrowing the scope of the problem and introducing data. 1.3.3 Second Example As another example, but this time using a social context, is the University of California - Berkeley admission bias question. Running this as a lesson would look like this: 1.3.3.1 Problem: In the early 1970s there was a concern that the University of California - Berkeley was discriminating in its admissions process based on gender. Question: How do we decide if Cal-Berkeley is practicing discrimination based on gender? Take some time and discuss how to answer the question. 1.3.3.2 Discussion ideas: There are many ways to try to answer this question. Someone might say that Berkeley had to be because this was the early 1970s and we know that institutional bias against women was common. This is known as butterfly reasoning. This is not analytical reasoning. We must collect some data that will help us in deciding the answer. In practice the is an iterative process. 1.3.4 Other problem ideas: In mathematics, deciding if a function is continuous at a point. Generate a visual of a function and have an epsilon selected at random. The decision maker must determine if there is a delta such that for all the points inside delta of x, the function is within epsilon of the limit. In political science, we could use voter data to ask questions about coastal states versus central states. In biology, we could look at sports data such as Olympic race times. In engineering, we can look at strength of materials, completion times of projects, or design selection. 1.3.5 Using Analytic Reasoning. We need data and a metric to help us answer the question of who is the better batter. There are many different ways to gather the data but this should be based on the metric we use. In sports analytics, there are many metrics that can be used to compare players, but for ease and the sake of an interesting analysis, we will use batting average. To make the problem even easier, we will provide the raw data from the years 1995 and 1996. Some students may object to this simplified data and you can use these objections as points of discussion on the importance of data that represents the question being asked. 1.3.5.1 Information Gathering Here is the code to generate the raw data for both batters. The reason we are generating the data is that we simply have the summary data from the records and this is not how data is often obtained. The information gathering and cleaning can often represent a significant time investment. This is often lost on students as data is presented to them in a clean format because of class time concerns. To give the students a sense of the work involved, generate the raw data using the code below, and then give the csv file to them. First, we will generate a simple frequency form of the data, we are actually working backwards from how you would typically proceed in your analysis but this is done to save you time as an instructor. For this section we will need several packages; let’s load them first. library(vcd) library(vcdExtra) library(dplyr) MLB_freq&lt;-data.frame(expand.grid(Player=c(&quot;Derek Jeter&quot;,&quot;David Justice&quot;), Year=c(&quot;1995&quot;,&quot;1996&quot;),Result=c(&quot;Hit&quot;,&quot;Out&quot;)), count=c(12,104,183,45,48-12,411-104,582-183,140-45)) knitr::kable(MLB_freq) Player Year Result count Derek Jeter 1995 Hit 12 David Justice 1995 Hit 104 Derek Jeter 1996 Hit 183 David Justice 1996 Hit 45 Derek Jeter 1995 Out 36 David Justice 1995 Out 307 Derek Jeter 1996 Out 399 David Justice 1996 Out 95 MLB_long&lt;-expand.dft(MLB_freq,freq=&quot;count&quot;) head(MLB_long) ## Player Year Result ## 1 Derek Jeter 1995 Hit ## 2 Derek Jeter 1995 Hit ## 3 Derek Jeter 1995 Hit ## 4 Derek Jeter 1995 Hit ## 5 Derek Jeter 1995 Hit ## 6 Derek Jeter 1995 Hit Now let’s random shuffle to give the appearance of collected data. Note: we are using the dplyr package to complete this work. table(MLB_long$Year) ## ## 1995 1996 ## 459 722 set.seed(81) MLB_long&lt;-MLB_long %&gt;% sample_frac() %&gt;% arrange(Year) head(MLB_long) ## Player Year Result ## 1 Derek Jeter 1995 Hit ## 2 David Justice 1995 Out ## 3 David Justice 1995 Out ## 4 David Justice 1995 Hit ## 5 David Justice 1995 Out ## 6 David Justice 1995 Out table(MLB_long) ## , , Result = Hit ## ## Year ## Player 1995 1996 ## David Justice 104 45 ## Derek Jeter 12 183 ## ## , , Result = Out ## ## Year ## Player 1995 1996 ## David Justice 307 95 ## Derek Jeter 36 399 Now to get the data to students you could use the write.csv function write.csv(MLB_long,&quot;./data/batting.csv&quot;) 1.3.5.2 Transformation (Re-representation) of Data The data is not in a form that will help make a decision. It is important to ask the students how they would transform the data to help make a decision. There are typically two responses to this request. The first is to get the batting averages for the two players. The second is to summarize the batting averages by each player within each year. This then begs the question of how to aggregate the two years. At this point, try to steer the students to comparing the batting averages within each year. They will note that David Justice has the higher in each year. The next question is how to transform this information into a single metric of overall batting averages. Also note at this point that our transformation is in the form of descriptive numeric summaries. This is often an important first step but in the next section we will work with visual representations of the data. Now, let’s first get the batting average for each year. 1.3.5.3 Problem How should we transform, summarize, the data in a manner that will help us make a decision? 1.3.5.3.1 Discussion Ideas There are many ways to summarize the data. The problem is that we have hits and outs whereas we need total at bats. If we create summary, we will not get an appropriate metric of performance. summary(MLB_long) ## Player Year Result ## David Justice:551 Min. :1995 Hit:344 ## Derek Jeter :630 1st Qu.:1995 Out:837 ## Median :1996 ## Mean :1996 ## 3rd Qu.:1996 ## Max. :1996 We are going have to transform the data. The first step would be to group the data by each of the variables. MLB_long %&gt;% dplyr::group_by(Year,Player,Result) %&gt;% dplyr::summarize(Total=n()) ## # A tibble: 8 x 4 ## # Groups: Year, Player [?] ## Year Player Result Total ## &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;int&gt; ## 1 1995 David Justice Hit 104 ## 2 1995 David Justice Out 307 ## 3 1995 Derek Jeter Hit 12 ## 4 1995 Derek Jeter Out 36 ## 5 1996 David Justice Hit 45 ## 6 1996 David Justice Out 95 ## 7 1996 Derek Jeter Hit 183 ## 8 1996 Derek Jeter Out 399 Or using different code knitr::kable(xtabs(~Player+Result+Year,MLB_long),caption = &quot;A Simple Table Summarizing Batting Performance&quot;) Table 1.1: A Simple Table Summarizing Batting Performance Player Result Year Freq David Justice Hit 1995 104 Derek Jeter Hit 1995 12 David Justice Out 1995 307 Derek Jeter Out 1995 36 David Justice Hit 1996 45 Derek Jeter Hit 1996 183 David Justice Out 1996 95 Derek Jeter Out 1996 399 This is a good first step but students will have to mentally try to find the total at bats, sum hits and outs, and then divide hits by at bats; see Table 1.1 and the simple table below it. As a preview of the visualization section, consider the following table and think about how it presents the information. ftable(xtabs(~Player+Year+Result,MLB_long)) ## Result Hit Out ## Player Year ## David Justice 1995 104 307 ## 1996 45 95 ## Derek Jeter 1995 12 36 ## 1996 183 399 It should be clear that it is hard to use these summaries to make a decision. In the next section we will discuss visualizing data to include the advantages and disadvantages of each type of table. But for now let’s complete the discussion of comparing batting averages. Next we need to get a batting average for each player in each year. prop.table(xtabs(~Player+Year+Result,MLB_long),1:2)[,,1] ## Year ## Player 1995 1996 ## David Justice 0.2530414 0.3214286 ## Derek Jeter 0.2500000 0.3144330 or as in Table 1.2. knitr::kable(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% select(-Result) %&gt;% mutate(Avg=round(Hits/At_Bats,4)) %&gt;% select(Player,Year,Avg) %&gt;% arrange(Year,desc(Player)),caption=&quot;Batting Average in each Year&quot;) Table 1.2: Batting Average in each Year Player Year Avg Derek Jeter 1995 0.2500 David Justice 1995 0.2530 Derek Jeter 1996 0.3144 David Justice 1996 0.3214 1.3.5.4 Discussion Ideas Ask the students to decide who is the better player based on the batting averages. The students should point out that David Justice had a better batting average in each year. You can ask how you should combine these averages? The students may claim that it does not matter since David Justice was better in each year. They may also want to take a simple average, which again would lead to David Justice being the better player. Other students will note that the overall batting average is found by dividing totals hits by total at bats. Let’s combine the hits and outs from each year by aggregating across years. prop.table(xtabs(~Player+Result,MLB_long),1)[,1] ## David Justice Derek Jeter ## 0.2704174 0.3095238 knitr::kable(MLB_long %&gt;% group_by(Player,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player) %&gt;% summarise(Total=n()),by=&quot;Player&quot;) %&gt;% select(-Result) %&gt;% mutate(Avg=round(Hits/Total,4)) %&gt;% select(Player,Avg) %&gt;% arrange(desc(Player)),caption=&quot;Combined Batting Average for Both Years&quot;) Table 1.3: Combined Batting Average for Both Years Player Avg Derek Jeter 0.3095 David Justice 0.2704 From Table 1.3 it now appears that Derek Jeter is the better player. Who is the better player? Why did we get different results depending on the summary? What concerns do you have with the summaries and data transformations we created? "],
["Viz1.html", "1.4 Visualizing data (Re-representation)", " 1.4 Visualizing data (Re-representation) We are still in the transformation or re-representation of information phase. Visualization helps in this phase of the analysis project. We will present many different types of visualizations and this is a transition to the next phase of the analysis titled manipulation. Having to write code over and over with small changes will lead us to the interaction phase. We will first address visualization. Although some authors would not consider tables as a visualization of data, we do. In this section, we will use two different forms of visualization, both a table and a vector plot. 1.4.1 Background on Visualizing Data Data visualization is a complicated and important subject. You can get advanced degrees in the subject. We will only give the basics principles and ideas in this section. There are three things that should always inform the visual summary you select and/or design. First, you must decide which ideas are important to communicate to the reader. This requires you to identify your key message, filter and summarize the data to a point that maintains that message without over-compressing the data, and finally think about how to communicate this idea. Second, what is the reader’s background and how will they understand or what will they take away from the visualization? Tufte states that you should “respect your audience”. Think about such factors as how short-term memory limits the amount of information a reader can hold and how preattentive thought quickly picks up position, motion, shape, and color first. Finally, consider the data type(s), what are the advantages and disadvantages of the data, what information is contained in the data, and what tools are needed to visualize this data? For example, color does a nice job with discrete variables although it could be used as a gradient for continuous variables. Length is good for continuous variables. Area is difficult for readers to compare although rectangular is not as difficult because of the linear comparison of each side. Figure 1.2, adopted from Friendly and Meyer (2016), is an excellent framework for thinking about visualization. Often, we first start in the analysis phase. For our current problem we are in the analysis phase with comparison being the primary design principle; we want to compare Derek Jeter to David Justice. At the end of the analysis we must present the results and this puts us in the presentation section. In each case the reader is different. In the analysis phase, we, the analyst, are the reader and maybe a few others on the analysis team. In the presentation, the readers can be from a variety of backgrounds often leading to a simpler presentation. Figure 1.2: Visualization Purposes 1.4.2 Using Problem In the batting average problem, we have compressed the results of individual bats into an average. There was also the choice to leave year as a separate variable or to compress further into a single summary. The compression to a batting average, weather accounting for year or not, lost an important element of the data and that is the magnitude of number of bats. Understanding our reader, in this case the analyst but ultimately any reader for presentation, we should expect that most people will consider the value of the batting averages for each player during each year to be of equal value, that is they assume that the number of at bats is approximately equal. Thus, in this example they will either compare Derek Jeter against David Justice each year or simply average the two years into a single number to make a decision on the better batter. In either case, the reader may conclude that David Justice is the better batter. In developing our visual summaries we will have to take this into consideration. 1.4.3 Discussion ideas The tables in the previous section are visual summaries but what are the limitations? What are the key idea(s) for this problem? How would you visualize this data? Most students will only think about tables. In considering tables, how should the variables be ordered? That is, which variables should be rows and which should be columns? Should you use shading in the tables? 1.4.4 Visualization We will examine two ways to visualize the data in our batting average problem. First we will continue to look at the tables and then move to a visualization that utilizes vectors. 1.4.4.1 Tables for Visualization In this section we will go through a series of tables and discuss advantages and disadvantages of each. 1.4.4.1.1 First Table The first table from the software is a default and looks like table(MLB_long) ## , , Result = Hit ## ## Year ## Player 1995 1996 ## David Justice 104 45 ## Derek Jeter 12 183 ## ## , , Result = Out ## ## Year ## Player 1995 1996 ## David Justice 307 95 ## Derek Jeter 36 399 Ask your students about their thoughts on this table. Some ideas that may come include the lack of a title, the use of “, ,”, and having the split on result because it is difficult to mentally combine for comparison. Remember that the reader of this table is the analytic team. As an analyst, the use of “, ,”&quot; in the titles and the splitting of result into two table may not bother you but it is still inefficient. Plus you as the analyst want the ability to control how the variables are arranged. 1.4.4.1.2 Additional Tables Let’s start by finding a better representation of the table. ftable(table(MLB_long)) ## Result Hit Out ## Player Year ## David Justice 1995 104 307 ## 1996 45 95 ## Derek Jeter 1995 12 36 ## 1996 183 399 The advantage of this figure did not split the data. Note that the software automatically placed Player and Year in the rows. This placement makes it difficult to compare the years since they are separated by one line. Next, we will sort the variables by the comparison we want to make. In this case we want players within years. This is called effect-ordering sorting (Friendly and Kwan 2003). ftable(table(MLB_long),row.vars=c(&quot;Year&quot;,&quot;Player&quot;)) ## Result Hit Out ## Year Player ## 1995 David Justice 104 307 ## Derek Jeter 12 36 ## 1996 David Justice 45 95 ## Derek Jeter 183 399 As we discussed in Section 1.2, the transitions between analysis, visualization, and interaction may be a cycle. So next we need to get the number of at bats. data.frame(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% select(-Result) %&gt;% arrange(Year)) ## Player Year Hits At_Bats ## 1 David Justice 1995 104 411 ## 2 Derek Jeter 1995 12 48 ## 3 David Justice 1996 45 140 ## 4 Derek Jeter 1996 183 582 This is getting better although we lost year as an outer row variable and we still need average instead of hits. data.frame(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% mutate(Average=Hits/At_Bats) %&gt;% select(Year, Player,Average,At_Bats) %&gt;% arrange(Year)) ## Year Player Average At_Bats ## 1 1995 David Justice 0.2530414 411 ## 2 1995 Derek Jeter 0.2500000 48 ## 3 1996 David Justice 0.3214286 140 ## 4 1996 Derek Jeter 0.3144330 582 This is a nice summary and makes it clear that we have years with a small number of at bats. We still have to clean up some things to improve the visualization. What are some ideas to improve it? A caption should be provided with enough detail to describe the table. In addition, the default of 7 decimal places is too much. We will use 4 decimal places. knitr::kable(data.frame(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% mutate(Average=round(Hits/At_Bats,4)) %&gt;% select(Year, Player,Average,At_Bats) %&gt;% arrange(Year)),caption=&quot;Batting Averages and Total at Bats for Both Years&quot;) Table 1.4: Batting Averages and Total at Bats for Both Years Year Player Average At_Bats 1995 David Justice 0.2530 411 1995 Derek Jeter 0.2500 48 1996 David Justice 0.3214 140 1996 Derek Jeter 0.3144 582 Finally, we should combine both years. It is clear that we can’t just average the averages since the total at bats is different. We need to find the total hits and divide by the total at bats. This is Table 1.3 with the addition of the total at bats. knitr::kable(MLB_long %&gt;% group_by(Player,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player) %&gt;% summarise(At_Bats=n()),by=&quot;Player&quot;) %&gt;% select(-Result) %&gt;% mutate(Average=round(Hits/At_Bats,4)) %&gt;% select(Player,Average,At_Bats) %&gt;% arrange(desc(Player)),caption=&quot;Combined Batting Average for Both Years with Total at Bats&quot;) Table 1.5: Combined Batting Average for Both Years with Total at Bats Player Average At_Bats Derek Jeter 0.3095 630 David Justice 0.2704 551 The two players had similar number of at bats but Derek Jeter had the higher batting average. 1.4.5 Vectors for Visualization In the previous section, we learned that representing performance with just batting average is potentially misleading. The decimal representation of the average is too much of a compression because we lose the important information on the number of at bats. Carried to an extreme, if a player only batted twice and got one hit, batting average would be reported as a staggering 0.500. We attempted to remedy this by also reporting the total number of at bats along side of the batting average. The other issue we had was in the bias people use to combine batting averages. If only batting averages are reported, people tend to want to average them. However, since the number of at bats changes from year to year a weighted average is needed. In fact the way to determine overall average is to add the total number of hits and divide by the total number of at bats. If in the first year is \\({a \\over b}\\) and the second year is \\({c \\over d}\\), then the overall average is \\({(a+c) \\over (b+d)}\\). This is vector addition and gives another way to visualize the data; in the form of vectors and vector addition. 1.4.5.1 Discussion Ideas Now that we have described batting average, how to combine years, and the importance of the total at bats, is there a way to represent these in a plot? 1.4.5.2 Plot To plot both batting average and at bats is difficult so we will plot at bats on the x-axis and hits on the y-axis. In this case, the batting average is the angle, or the slope of the line. Angles are difficult to estimate but easy to compare. We used color to separate the two batters only for the combined years. We included the individual year breakdown but they are difficult to see. We included points to bring them out. The combination of years, or the calculation of combined batting average, is a vector addition and not the addition of fractions. Vectors have both direction and length. The direction is the number of hits over number of at bats, the traditional batting average. The length is related to the number of at bats, it is really the Pythagorean length which combines hits and total at bats. The plot shows that Derek Jeter’s combined batting average gets pulled more towards the second year where he had more at bats. The opposite is true for David Justice and that is why we get the reversal of batting averages when we compress from two years down to one. Figure 1.3: Visualization of Batting Averages This might be hard to see in the document so you can open it separately as pdf to see the design of the graph better. The link is http://bit.ly/2tP05tU 1.4.5.3 Discussion Ideas What do you like about the plot? What are the strengths and weaknesses? What changes would you make? Is it better to put the players’ years end to end or does that hide that David Justice is better in each individual year? Does the color help or hurt? The angle is the batting average, should we use white space in he graph and put an explanation into the graph? What if we had three years, how would we represent them? The labels overlap the lines, should we move or offset them? As a lead into the next lesson on interaction, selecting a year and turning it off as well as making lines more transparent could help. The problems with this graph are that the lines are close together, the font size on the axis is too small, the label points are hidden by the lines, and the aspect ratio is not one so that it appears that the average is closer to a 45 degree line which is an average of 1.000. 1.4.5.4 Plots in R You can construct these plots in R although they are a bit awkward. However on the positive side we can control the aspect ratio, offset text, and change the font size. To get an idea of how to do this consider the simple plot in Figure 1.4. plot(1,type=&quot;n&quot;,xlim=c(0,800),ylim=c(0,800),xlab=&quot;At Bats&quot;,ylab=&quot;Hits&quot;,asp=1) arrows(0,0,200,50,col=&quot;red&quot;) arrows(200,50,400,150,col=&quot;red&quot;) arrows(0,0,400,150,col=&quot;red&quot;) abline(0,1) Figure 1.4: Simple Example of visualization of Batting Averages Now using our data, Figure 1.5 shows that Derek Jeter is being pulled up to his 1996 average and David Justice is being pulled down to his 1995 average. plot(1,type=&quot;n&quot;,xlim=c(0,700),ylim=c(0,200),xlab=&quot;At Bats&quot;,ylab=&quot;Hits&quot;,asp=1) arrows(0,0,48,12,col=&quot;black&quot;) arrows(48,12,(48+582),(183+12),col=&quot;black&quot;) arrows(0,0,(48+582),(183+12),col=&quot;red&quot;) arrows(0,0,411,104,col=&quot;black&quot;) arrows(411,104,(411+140),(104+45),col=&quot;black&quot;) arrows(0,0,(411+140),(104+45),col=&quot;blue&quot;) abline(0,1) title(&quot;Comparing Batting Averages&quot;) legend(1, 250, legend=c(&quot;Derek Jeter&quot;, &quot;David Justice&quot;), col=c(&quot;red&quot;, &quot;blue&quot;),lty=c(1,1), cex=0.8) Figure 1.5: Comparing Batting Averages for Derek Jeter and David Justice We can improve the look of the plot by using the ggplot2 (Wickham and Chang 2016) package. First let’s get the data in a form to better using the plotting function. plotdata&lt;-data.frame(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% select(Year, Player,Hits,At_Bats) %&gt;% arrange(Year)) %&gt;% rbind(.,group_by(.,Player) %&gt;% summarise(Hits=sum(Hits),At_Bats=sum(At_Bats)) %&gt;% mutate(Year=&quot;Combined&quot;) %&gt;% select(Year, Player, Hits, At_Bats) ) Now Figure 1.6 compares the players. plotdata %&gt;% ggplot(aes(x=At_Bats,y=Hits)) + geom_point() + xlim(0,700)+ ylim(0,200)+ coord_fixed(ratio=1) + geom_segment(aes(x = 0, y = 0, xend = At_Bats, yend = Hits,color=Player),arrow=arrow(length=unit(.2,&#39;cm&#39;),type=&quot;closed&quot;)) + geom_text_repel(aes(x=At_Bats,y=Hits, label = Year)) + labs(title=&quot;Batting Averages&quot;) Figure 1.6: Comparing Batting Averages for Derek Jeter and David Justice (Using ggplot) 1.4.5.5 Discussion Ideas What do you like about Figure 1.6 as compared to Figure 1.5? What changes would you make? Is it better to put the players’ years end to end or does that hide that David Justice is better in each individual year? Does the color help or hurt? 1.4.5.6 More Discussion Ideas If you want to use external resources to help your students, the following are good references: http://junkcharts.typepad.com/junk_charts/ http://flowingdata.com/ http://www.storytellingwithdata.com/ References "],
["Inert1.html", "1.5 Interaction", " 1.5 Interaction The third phase of the analysis is to develop insight through manipulation of representations. In some sense we did this in section 1.4 by running different table and plots. This exercise was static and labor intensive. In this section we will introduce the use of interactive tools that reduce the need to re-write code. We will be using html widgets as this document is written in html. However, there are many other tools that can be used for interaction. 1.5.1 Background Information on Interaction The purpose of interaction in a visual display of data is the aid in the decision process. It can be used to explain a concept, develop conjectures or insights, and/or facilitate an exploration. This can lead to increased efficiencies and effectiveness of the decision making process. However, the science of understanding and implementing interaction is the least developed of the three areas. This is partly due to the only recent availability of software to easily develop customized interactive displays. The general principle of interaction is summarized as overview first, zoom on interest, filter to make specific, and provide details as required. Interaction can add in decision making because by interacting with the data; the analyst and decision maker can transform data, alter visual display, and then form hypothesis or alter conditions to determine impact. The biggest issue with interactivity is the ability to rapidly develop custom products. Currently this requires programming skills and sophisticated software. This will change, and has to some extent with packages such as Tableau, as more tools are developed that remove the need to program. 1.5.1.1 Simple Example To supplement this portion of the lesson, you may want to find interactive examples on the web. The following site has an example of a simple interactive visualization to help you facilitate a discussion on the effectiveness of an interactive to present an idea. “https://hbr.org/2014/04/what-the-scarcity-of-women-in-business-case-studies-really-looks-like”) 1.5.1.2 Discussion ideas What are the thoughts of the speed of the interaction? Did the animation help or hurt? What key idea did the authors want the reader to leave with from this visualization? What good make it better. 1.5.2 Our Problem We could develop two interactive methods to explore the problem. One for the tables and the other for the vector plots. 1.5.2.1 Interactive Tables We will generate several tables that a student can interact with in an html document. 1.5.2.1.1 First Table Our first attempt at interaction is to create a table where you can sort the columns. First we create the dataframe. interdata&lt;-data.frame(MLB_long %&gt;% group_by(Player,Year,Result) %&gt;% summarise(Hits=n()) %&gt;% filter(Result==&quot;Hit&quot;) %&gt;% left_join(MLB_long %&gt;% group_by(Player,Year) %&gt;% summarise(At_Bats=n()),by=c(&quot;Player&quot;,&quot;Year&quot;)) %&gt;% select(Year, Player,Hits,At_Bats) %&gt;% arrange(Year)) %&gt;% rbind(.,group_by(.,Player) %&gt;% summarise(Hits=sum(Hits),At_Bats=sum(At_Bats)) %&gt;% mutate(Year=&quot;Combined&quot;) %&gt;% select(Year, Player, Hits, At_Bats) ) %&gt;% mutate(Average=round(Hits/At_Bats,4)) Next we generate the table using the DT package (Xie 2016). DT::datatable(interdata) 1.5.2.1.2 Discussion Ideas Have the students experiment with the table. some examples are to use the sorting arrows to sort by player first then year or subset the data to only show Derek Jeter, note use the search window. What are the advantages and disadvantages of this interactive table? 1.5.2.1.3 Second Interactive Table For the second table we will use a pivot table using the rpivotTable package (Martoglio 2017). By default, we have fractions as a function of row totals. rpivotTable(MLB_long,rows=c(&quot;Year&quot;,&quot;Player&quot;),cols=&quot;Result&quot;,aggregatorName=&quot;Count as Fraction of Rows&quot;) 1.5.2.1.4 Discussion Ideas Have the students first remove year to get the batting averages for each player. Now ask the students to experiment with the pulldown menus to create other summaries; sort using the small areas next to the aggregation pulldown menu; switch year and player and determine the output. 1.5.2.2 Interactive Vector Plots Without developing our own custom visualization of the vector plot, which we could do in geogebra or using the R package shiny(Chang et al. 2017), we decided to find an existing application on the web. There is an interactive visualization application in the geogebra library, go to https://www.geogebra.org/m/YrPAV6KK. The example uses shooting baskets but gives the same idea as the reversal we saw in our problem. We selected this interaction because it helps explain why the reversal occurs and the conditions under which it occurs. 1.5.2.3 Discussion ideas Have the participants move Lucy1 around by experimenting with the length and angle to determine when the reversal occurs. What is the relationship between angle and the reversal? What is the relationship between length and reversal? Is it possible to have Tom as the better shooter regardless of Lucy’s actions as long as Lucy’s first and second day performances are less than Tom’s? What are the strengths of the interaction tool? What would have to be done to use it for our data? References "],
["final-product.html", "1.6 Final Product", " 1.6 Final Product The fourth phase of the analysis is the creation of a knowledge product. In this case the reader(s) will be varied. It is important to think about graphic design elements such as color, labels, font. The key point is to clearly define the message and then use the graphic elements to support this message. 1.6.1 Discussion Ideas What is the key message? What is the best method to communicate this message? Should we use a static graphic or an interactive display? 1.6.2 First Knowledge Product We think the key message is that Derek Jeter is the better batter than David Justice. We will use a static visual since interactive tools currently require access to the internet of special software. Before coming up with our final knowledge product we will discuss ideas using our vector plot from Figure 1.6, reproduced below. plotdata %&gt;% ggplot(aes(x=At_Bats,y=Hits)) + geom_point() + xlim(0,700)+ ylim(0,200)+ coord_fixed(ratio=1) + geom_segment(aes(x = 0, y = 0, xend = At_Bats, yend = Hits,color=Player),arrow=arrow(length=unit(.2,&#39;cm&#39;),type=&quot;closed&quot;)) + geom_text_repel(aes(x=At_Bats,y=Hits, label = Year)) + labs(title=&quot;Batting Averages&quot;) First let’s change the theme to reduce the background color. plotdata %&gt;% ggplot(aes(x=At_Bats,y=Hits)) + geom_point() + xlim(0,700)+ ylim(0,200)+ coord_fixed(ratio=1) + geom_segment(aes(x = 0, y = 0, xend = At_Bats, yend = Hits,color=Player),arrow=arrow(length=unit(.2,&#39;cm&#39;),type=&quot;closed&quot;)) + geom_text_repel(aes(x=At_Bats,y=Hits, label = Year)) + labs(title=&quot;Batting Averages&quot;)+ theme_minimal() Now let’s improve the labels. plotdata %&gt;% ggplot(aes(x=At_Bats,y=Hits)) + geom_point() + xlim(0,700)+ ylim(0,200)+ coord_fixed(ratio=1) + geom_segment(aes(x = 0, y = 0, xend = At_Bats, yend = Hits,color=Player),arrow=arrow(length=unit(.2,&#39;cm&#39;),type=&quot;closed&quot;)) + geom_text_repel(aes(x=At_Bats,y=Hits, label = Year)) + labs(title=&quot;Derek Jeter is Better than David Justice&quot;,x=&quot;Number of At Bats&quot;,y=&quot;Hits&quot;, subtitle=&quot;Batting averages for 1995 and 1996 as well as the combined averages&quot;)+ theme_minimal() Finally, let’s change the ticks on the axes and a different theme. plotdata %&gt;% ggplot(aes(x=At_Bats,y=Hits)) + geom_point() + ylim(0,200)+ coord_fixed(ratio=1) + geom_segment(aes(x = 0, y = 0, xend = At_Bats, yend = Hits,color=Player),arrow=arrow(length=unit(.2,&#39;cm&#39;),type=&quot;closed&quot;)) + geom_text_repel(aes(x=At_Bats,y=Hits, label = Year)) + labs(title=&quot;Derek Jeter is Better than David Justice&quot;,x=&quot;Number of At Bats&quot;,y=&quot;Hits&quot;, subtitle=&quot;Batting averages for 1995 and 1996 as well as the combined averages&quot;)+ theme_bw() + scale_x_continuous(breaks=seq(0,600,50)) 1.6.3 Discussion Ideas What do you like and dislike about the latest visual? Does it accomplish it goal of showing Derek Jeter is the better batter? What would you change? 1.6.4 Second Knowledge Product d=data.frame(x1=c(0,0), y2=c(0.3095,0.2704), y1=c(0,0), x2=c(.630,0.551), Player=c(&#39;Derek Jeter&#39;,&#39;David Justice&#39;), r=c(630,551)) ggplot(d) + geom_rect(aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=Player), color=&quot;black&quot;, alpha=0.5) + theme_classic() + scale_fill_brewer(palette=&quot;Paired&quot;) + facet_grid(. ~ Player) + scale_x_continuous(name=&quot;At Bats&quot;) + scale_y_continuous(name=&quot;Batting Average&quot;) + #geom_text(data=d, aes(x=x1+(x2-x1)/2, y=y1+(y2-y1)/2, label=r), size=4) + labs(title=&quot;Derek Jeter is a batter batter than David Justice&quot;, subtitle=&quot;Based on data from the years 1995 - 1996&quot;) + geom_text(aes(x=x1+(x2-x1)/2, y=y1-0.01, label=r)) + theme(axis.text.x = element_blank(),axis.ticks.x = element_blank(),legend.position = &quot;none&quot;) d=data.frame(x1=c(0,0), y2=c(0.3095,0.2704), y1=c(0,0), x2=c(.630,0.551), Player=c(&#39;Derek Jeter&#39;,&#39;David Justice&#39;), r=c(630,551)) ggplot(d) + geom_rect(aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=Player), color=&quot;black&quot;, alpha=0.5) + theme_classic() + scale_fill_brewer(palette=&quot;Paired&quot;) + facet_grid(. ~ Player) + scale_x_continuous(name=&quot;At Bats&quot;,breaks=c(0,.25,.5,.75),labels=c(&quot;0&quot;, &quot;250&quot;, &quot;500&quot;,&quot;750&quot;)) + scale_y_continuous(name=&quot;Batting Average&quot;) + labs(title=&quot;Derek Jeter is a batter batter than David Justice&quot;, subtitle=&quot;Based on data from the years 1995 - 1996&quot;) + theme(legend.position = &quot;none&quot;) 1.6.5 Web Resources The following are some resource https://www.r-bloggers.com/r-how-to-layout-and-design-an-infographic/ http://nandeshwar.info/data-visualization/how-to-create-infographics-in-r/ http://flowingdata.com/category/tutorials/ "],
["Conc1.html", "1.7 Conclusion", " 1.7 Conclusion In conclusion of this section go back over the objectives and ask participants to explain and discuss. Objectives After the training, participants will: be able to define and explain visual analytics be able to describe the three important components of visual analytics be able to discuss types of unique insights that VA can provide "],
["Chpt2.html", "Chapter 2 Exploratory Visual Analytics", " Chapter 2 Exploratory Visual Analytics “It isn’t accidental that when we begin to understand something we say ‘I see.’ Not ‘I hear’ or ‘I smell’” – Stephen Few “You see alot just by looking” – Yogi Berra Visualization can surprise but doesn’t scale well. Modeling scales well but cannot surprise you. – Hadley Wickham This chapter starts with visualization and explores relationships between variables. Ultimately, we will be recreating a chart similar to Hans Rosling’s famous animated visualization from his TED talk. We will be using R to generate the display however, if you don’t want to use R go the gapminder website, https://www.gapminder.org/, and under the header tools, you will have access to all the data as well as an interactive scatter plot. Another avenue you could explore is to use data directly from the World Bank. On their website you can create interactive visual displays, https://data.worldbank.org/. "],
["lesson-preparation-1.html", "2.1 Lesson Preparation", " 2.1 Lesson Preparation 2.1.1 Objectives: After the training, students will: explain the basic principles of visual displays of data be able to generate an animated visualization be able to evaluate and compare visual displays of data 2.1.2 Preparation Prior to class, complete the following 1. Watch the video from Hans Rosling entitled “The best stats you’ve ever seen” . Go to the gapminder website and under the tab tools, experiment with the data. "],
["Intro2.html", "2.2 Lesson Introduction", " 2.2 Lesson Introduction Suggestions to start the lesson: In the video, Rosling mentions that his students believe that developed countries have long life expectancies and low birth rates while developing countries are the opposite. What are some other distinctions between these categories? There are many ways to answer this question and your students may talk about GPD, infant mortality rates, and age of population. What do you think made Hans Rosling’s presentation so effective? What did you like about the visualizations? What are some of the design principles you learned from this video? We are replicating Figure 1.1 below to remind you of the process for visual analytics. We are assuming that you have read Chapter @ref(#Chpt1) even if you did not use the material. In this lesson we will be jumping into the visualization portion of the cycle first in an attempt to find insight. We are looking for a way to determine developed and developing countries and watch their progression over time. Thus we will go to analytical reasoning and interaction after starting with the visualization. We must start with data collection first. "],
["data-collection.html", "2.3 Data Collection", " 2.3 Data Collection The data for this lesson comes from the Gapminder website. Again, you could just start with the tools application on the website instead of using the R code here. This section will be long but remember that data wrangling can take up to 80% of the time in a project. We also provide the final data in a csv file on the github site for this book. The file name is Gapminder_final.csv. 2.3.1 Load Packages First we will load two packages we need. The data is downloaded in a Excel spreadsheet; we will use the package readxl to read it. In addition, R has a package called gapminder which is a subset of the data from the Gapminder website. We will use it to get country names to reduce the size of our data and exclude countries with a large amount of missing data. library(readxl) library(gapminder) library(tidyverse) The data has been downloaded and is in the data folder on the GitHub site for this book. 2.3.2 Population We will read the data in first. gapminder_population_temp &lt;- read_excel(&quot;data/indicator gapminder population.xlsx&quot;) Let’s look at the first few rows of the data. Total population 1800.0 1810.0 1820.0 1830.0 1840.0 1850.0 1860.0 1870.0 1880.0 1890.0 1900.0 1910.0 1920.0 1930.0 1940.0 1950.0 1951.0 1952.0 1953.0 1954.0 1955.0 1956.0 1957.0 1958.0 1959.0 1960.0 1961.0 1962.0 1963.0 1964.0 1965.0 1966.0 1967.0 1968.0 1969.0 1970.0 1971.0 1972.0 1973.0 1974.0 1975.0 1976.0 1977.0 1978.0 1979.0 1980.0 1981.0 1982.0 1983.0 1984.0 1985.0 1986.0 1987.0 1988.0 1989.0 1990.0 1991.0 1992.0 1993.0 1994.0 1995.0 1996.0 1997.0 1998.0 1999.0 2000.0 2001.0 2002.0 2003.0 2004.0 2005.0 2006.0 2007.0 2008.0 2009.0 2010.0 2011.0 2012.0 2013.0 2014.0 2015.0 Abkhazia NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA Afghanistan 3280000 3280000 3323519 3448982 3625022 3810047 3973968 4169690 4419695 4710171 5021241 5351413 5813814 6394908 7034081 7752118 7839426 7934798 8038312 8150037 8270024 8398309 8534913 8679848 8833127 8994793 9164945 9343772 9531555 9728645 9935358 10148841 10368600 10599790 10849510 11121097 11412821 11716896 12022514 12315553 12582954 12831361 13056499 13222547 13283279 13211412 12996923 12667001 12279095 11912510 11630498 11438949 11337932 11375768 11608351 12067570 12789374 13745630 14824371 15869967 16772522 17481800 18034130 18511480 19038420 19701940 20531160 21487079 22507368 23499850 24399948 25183615 25877544 26528741 27207291 27962207 28809167 29726803 30682500 31627506 32526562 Akrotiri and Dhekelia NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 10661 10737 10813 10889 10966 11043 11121 11200 11279 11358 11439 11519 11601 11683 11765 11848 11932 12016 12101 12187 12273 12359 12447 12535 12623 12712 12802 12892 12983 13075 13167 13260 13354 13448 13543 13639 13735 13832 13930 14028 14127 14227 14328 14429 14531 14633 14737 14841 14946 15051 15157 15264 15372 15481 15590 15700 15700 15700 15700 NA NA NA NA NA NA NA Albania 410445 423591 438671 457234 478227 506889 552800 610036 672544 741688 819950 901122 963956 1015991 1123210 1263171 1287499 1316086 1348097 1382881 1419969 1459089 1500152 1543224 1588478 1636054 1685901 1737645 1790533 1843596 1896125 1947786 1998695 2049147 2099657 2150602 2202040 2253842 2305999 2358467 2411229 2464338 2517869 2571845 2626290 2681245 2735329 2788315 2842620 2901590 2966799 3041003 3121336 3197064 3253659 3281453 3275438 3240613 3189623 3140634 3106727 3092034 3092471 3102898 3114851 3121965 3124093 3123112 3117045 3103758 3082172 3050741 3010849 2968026 2929886 2901883 2886010 2880667 2883281 2889676 2896679 Algeria 2503218 2595056 2713079 2880355 3082721 3299305 3536468 3811028 4143163 4525691 4946166 5404045 6063800 6876190 7797418 8872247 9039913 9216395 9405445 9609507 9829717 10065829 10316288 10578453 10848971 11124892 11404859 11690152 11985130 12295973 12626953 12980269 13354197 13744383 14144437 14550033 14960111 15377095 15804428 16247113 16709098 17190236 17690184 18212331 18760761 19337723 19943667 20575701 21228288 21893857 22565908 23241276 23917889 24591493 25257671 25912364 26554277 27180921 27785977 28362015 28904300 29411839 29887717 30336880 30766551 31183658 31590320 31990387 32394886 32817225 33267887 33749328 34261971 34811059 35401790 36036159 36717132 37439427 38186135 38934334 39666519 American Samoa 8170 8156 8142 8128 8114 7958 7564 7057 6582 6139 5949 7047 8173 10081 13135 18937 19295 19543 19683 19729 19706 19647 19597 19606 19729 20012 20478 21118 21883 22701 23518 24320 25116 25886 26615 27292 27916 28490 29014 29491 29932 30325 30690 31105 31670 32456 33488 34740 36165 37687 39247 40835 42448 44049 45591 47044 48379 49597 50725 51807 52874 53926 54942 55899 56768 57522 58176 58729 59117 59262 59117 58648 57904 57031 56226 55636 55316 55227 55302 55434 55538 From the gapminder package, we will get the subset of countries where the data is most complete. countries&lt;-levels(gapminder$country) Finally, we will wrangle the data into the final form needed. gapminder_population&lt;-gapminder_population_temp %&gt;% gather(year,pop,-&quot;Total population&quot;) %&gt;% rename(country=&quot;Total population&quot;) %&gt;% mutate(year=as.integer(year),pop=as.integer(pop)) %&gt;% filter(country %in% countries,year&gt;=1950) Table 2.1 is the first 6 rows of our data. Table 2.1: Population Data Arranged into Rows country year pop Afghanistan 1950 7752118 Albania 1950 1263171 Algeria 1950 8872247 Angola 1950 4354882 Argentina 1950 17150335 Australia 1950 8177344 Before proceeding. We will check the quality of the data. length(countries) ## [1] 142 length(unique(gapminder_population$country)) ## [1] 139 There are 142 countries in the gapminder data but only 139 in the data we collected that match those 142 countries. There might some names in gapminder that are different from those from the imported data. We will check this idea first. countries[!(countries %in% unique(gapminder_population$country))] ## [1] &quot;Korea, Dem. Rep.&quot; &quot;Korea, Rep.&quot; &quot;Yemen, Rep.&quot; We are missing the two Koreas and Yemen from our data. We need the full list of countries in the original data to change the names. gapminder_population&lt;-gapminder_population_temp %&gt;% gather(year,pop,-&quot;Total population&quot;) %&gt;% rename(country=&quot;Total population&quot;) %&gt;% mutate(year=as.integer(year),pop=as.integer(pop)) %&gt;% filter(year&gt;=1950) unique(gapminder_population$country)[grep(&quot;Korea&quot;,unique(gapminder_population$country))] ## [1] &quot;North Korea&quot; &quot;South Korea&quot; &quot;United Korea (former)&quot; unique(gapminder_population$country)[grep(&quot;Yemen&quot;,unique(gapminder_population$country))] ## [1] &quot;North Yemen (former)&quot; &quot;South Yemen (former)&quot; &quot;Yemen&quot; We now know the problem is that in the gapminder package we have the titles “Korea, Dem. Rep.” “Korea, Rep.” “Yemen, Rep.” while in our data from the gapminder website we have the names “North Korea” “South Korea” “Yemen” We will correct the names in the our data. gapminder_population$country&lt;-gsub(&quot;North Korea&quot;,&quot;Korea, Dem. Rep.&quot;,gapminder_population$country) gapminder_population$country&lt;-gsub(&quot;South Korea&quot;,&quot;Korea, Rep.&quot;,gapminder_population$country) gapminder_population$country&lt;-gsub(&quot;Yemen&quot;,&quot;Yemen, Rep.&quot;,gapminder_population$country) We will check our data again. sum(!(countries %in% unique(gapminder_population$country))) ## [1] 0 Finally we will get rid of the countries not in the gapminder package. gapminder_population&lt;-gapminder_population %&gt;% filter(country %in% countries) Next we will look for missing observations. gapminder_population[is.na(gapminder_population$pop),] ## # A tibble: 2 x 3 ## country year pop ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Taiwan 2014 NA ## 2 Taiwan 2015 NA We are missing the last two years of data for Taiwan. We could drop Taiwan or get another estimate of the population from the web. Using the website http://www.worldometers.info/world-population/taiwan-population/ we see that for the last four years the population has grown by about 70000 each year. So we will estimate the population for 2014 and 2015 by adding 70000 to the population in 2013 for each year.. gapminder_population[is.na(gapminder_population$pop),][1,3]=23151000 + 70000 gapminder_population[is.na(gapminder_population$pop),][1,3]=23151000 + 140000 Now we need to add the continents to the data frame. First we will get the country names and associated continent names from the gapminder package. dict&lt;-gapminder %&gt;% group_by(continent) %&gt;% distinct(country) %&gt;% mutate(country=as.character(country)) Now we can add the continent names using a join function. gapminder_population &lt;- gapminder_population %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,pop) Table 2.2 shows the form of the final data set. Table 2.2: Final Population Data country continent year pop Afghanistan Asia 1950 7752118 Albania Europe 1950 1263171 Algeria Africa 1950 8872247 Angola Africa 1950 4354882 Argentina Americas 1950 17150335 Australia Oceania 1950 8177344 Clean up by removing temporary objects. rm(gapminder_population_temp) 2.3.3 Life Expectancy Next we bring in life expectancy data and since the source is the same we will have the same issue with the names of the Koreas and Yemen. gapminder_lifeexp_temp &lt;- read_excel(&quot;data/indicator life_expectancy_at_birth.xlsx&quot;) gapminder_lifeexp&lt;-gapminder_lifeexp_temp %&gt;% gather(year,life_exp,-&quot;Life expectancy&quot;) %&gt;% rename(country=&quot;Life expectancy&quot;) %&gt;% mutate(year=as.integer(year)) %&gt;% filter(year&gt;=1950) rm(gapminder_lifeexp_temp) gapminder_lifeexp$country&lt;-gsub(&quot;North Korea&quot;,&quot;Korea, Dem. Rep.&quot;,gapminder_lifeexp$country) gapminder_lifeexp$country&lt;-gsub(&quot;South Korea&quot;,&quot;Korea, Rep.&quot;,gapminder_lifeexp$country) gapminder_lifeexp$country&lt;-gsub(&quot;Yemen&quot;,&quot;Yemen, Rep.&quot;,gapminder_lifeexp$country) gapminder_lifeexp&lt;-gapminder_lifeexp %&gt;% filter(country %in% countries) sum(is.na(gapminder_lifeexp)) ## [1] 0 gapminder_lifeexp &lt;- gapminder_lifeexp %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,life_exp) Again @ref(tab:tab-life_exp) shows the final data set. (#tab:tab-life_exp)Final Life Expectancy Data country continent year life_exp Afghanistan Asia 1950 26.85 Albania Europe 1950 54.48 Algeria Africa 1950 42.77 Angola Africa 1950 30.70 Argentina Americas 1950 61.61 Australia Oceania 1950 69.01 2.3.4 Fertility Rates Next is fertility rates. gapminder_fertility_temp &lt;- read_excel(&quot;data/indicator undata total_fertility.xlsx&quot;) gapminder_fertility&lt;-gapminder_fertility_temp %&gt;% gather(year,fertility,-&quot;Total fertility rate&quot;) %&gt;% rename(country=&quot;Total fertility rate&quot;) %&gt;% mutate(year=as.integer(year)) %&gt;% filter(year&gt;=1950) rm(gapminder_fertility_temp) gapminder_fertility$country&lt;-gsub(&quot;North Korea&quot;,&quot;Korea, Dem. Rep.&quot;,gapminder_fertility$country) gapminder_fertility$country&lt;-gsub(&quot;South Korea&quot;,&quot;Korea, Rep.&quot;,gapminder_fertility$country) gapminder_fertility$country&lt;-gsub(&quot;Yemen&quot;,&quot;Yemen, Rep.&quot;,gapminder_fertility$country) gapminder_fertility&lt;-gapminder_fertility %&gt;% filter(country %in% countries) length(unique(gapminder_fertility$country)) ## [1] 142 We need to check for missing values. sum(is.na(gapminder_fertility$fertility)) ## [1] 2 gapminder_fertility[is.na(gapminder_fertility$fertility),] ## # A tibble: 2 x 3 ## country year fertility ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Taiwan 2014 NA ## 2 Taiwan 2015 NA It is the country of Taiwan again that has missing values. I will estimate the fertility with average of the previous 5 years. temp&lt;-as.double(gapminder_fertility %&gt;% filter(country==&quot;Taiwan&quot;,year&lt;2014 &amp; year&gt;2008) %&gt;% summarise(ave=mean(fertility))) gapminder_fertility&lt;-gapminder_fertility %&gt;% replace_na(list(fertility=temp)) rm(temp) gapminder_fertility &lt;- gapminder_fertility %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,fertility) Table 2.3 is the final form of the fertility data. Table 2.3: Final Fertility Data country continent year fertility Afghanistan Asia 1950 7.67 Albania Europe 1950 5.80 Algeria Africa 1950 7.65 Angola Africa 1950 6.93 Argentina Americas 1950 3.16 Australia Oceania 1950 3.07 2.3.5 Child Mortality Next we will collect data on child mortality. This data is the number of children out of 1000 born in the given year that will die before reaching the age of 5. gapminder_mortality5_temp &lt;- read_excel(&quot;data/indicator gapminder under5mortality.xlsx&quot;) gapminder_mortality5&lt;-gapminder_mortality5_temp %&gt;% gather(year,mortality,-&quot;Under five mortality&quot;) %&gt;% rename(country=&quot;Under five mortality&quot;) %&gt;% mutate(year=as.integer(year)) %&gt;% filter(year&gt;=1950) rm(gapminder_mortality5_temp) gapminder_mortality5$country&lt;-gsub(&quot;North Korea&quot;,&quot;Korea, Dem. Rep.&quot;,gapminder_mortality5$country) gapminder_mortality5$country&lt;-gsub(&quot;South Korea&quot;,&quot;Korea, Rep.&quot;,gapminder_mortality5$country) gapminder_mortality5$country&lt;-gsub(&quot;Yemen&quot;,&quot;Yemen, Rep.&quot;,gapminder_mortality5$country) gapminder_mortality5&lt;-gapminder_mortality5 %&gt;% filter(country %in% countries) gapminder_mortality5 ## # A tibble: 9,372 x 3 ## country year mortality ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1950 440 ## 2 Albania 1950 165 ## 3 Algeria 1950 292 ## 4 Angola 1950 405 ## 5 Argentina 1950 93.5 ## 6 Australia 1950 31.6 ## 7 Austria 1950 75.3 ## 8 Bahrain 1950 306 ## 9 Bangladesh 1950 353 ## 10 Belgium 1950 59.3 ## # ... with 9,362 more rows We need to check for missing values. sum(is.na(gapminder_mortality5$mortality)) ## [1] 156 gapminder_mortality5[is.na(gapminder_mortality5$mortality),] ## # A tibble: 156 x 3 ## country year mortality ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Hong Kong, China 1950 NA ## 2 Puerto Rico 1950 NA ## 3 Reunion 1950 NA ## 4 Taiwan 1950 NA ## 5 Hong Kong, China 1951 NA ## 6 Puerto Rico 1951 NA ## 7 Reunion 1951 NA ## 8 Taiwan 1951 NA ## 9 Hong Kong, China 1952 NA ## 10 Puerto Rico 1952 NA ## # ... with 146 more rows Now Hong Kong, Puerto Rico, and Reunion are missing data up through the year 1979 and Taiwan is missing all years. We could drop Taiwan from the data but that is a waste of the data sets. We could impute the values but we need to be careful when we interpret the resulting plots. The other three countries are going to impose problems for the years prior to 1980. For ease will will drop these countries from the analysis after we get our final data set. ` gapminder_mortality5 &lt;- gapminder_mortality5 %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,mortality) gapminder_mortality5 %&gt;% head() %&gt;% knitr::kable() country continent year mortality Afghanistan Asia 1950 439.56 Albania Europe 1950 165.17 Algeria Africa 1950 292.13 Angola Africa 1950 404.92 Argentina Americas 1950 93.53 Australia Oceania 1950 31.60 2.3.6 Aging Population Another thought is developed countries have an older population by percentage. We will next collect data on the percent of population above 60 years in age. gapminder_above60_temp &lt;- read_excel(&quot;data/indicator_total above 60 percen.xlsx&quot;) gapminder_above60&lt;-gapminder_above60_temp %&gt;% gather(year,above_60,-&quot;Total above 60 (%)&quot;) %&gt;% rename(country=&quot;Total above 60 (%)&quot;) %&gt;% mutate(year=as.integer(year)) %&gt;% filter(year&gt;=1950) rm(gapminder_above60_temp) This data came from a different source, so we need to be careful about the country names and which ones are contained in the data set. countries[!countries %in% unique(gapminder_above60$country)] ## [1] &quot;Central African Republic&quot; &quot;Czech Republic&quot; ## [3] &quot;Dominican Republic&quot; &quot;Taiwan&quot; Taiwan is still a problem but now we have three other countries that are in the gapminder package and not in the new data set. Let’s remove all the countries that are causing us problems. countries&lt;- countries[!countries %in% unique(c(unique(gapminder_mortality5[is.na(gapminder_mortality5$mortality),]$country), countries[!countries %in% unique(gapminder_above60$country)]))] gapminder_above60&lt;-gapminder_above60 %&gt;% filter(country %in% countries) sum(is.na(gapminder_above60$above_60)) ## [1] 0 There are no missing values. But the data is only for every 5 years and has projections past 2015. unique(gapminder_above60$year) ## [1] 1950 1955 1960 1965 1970 1975 1980 1985 1990 1995 2000 2005 2010 2015 ## [15] 2020 2025 2030 2035 2040 2045 2050 We will first remove the projections. gapminder_above60 &lt;- gapminder_above60 %&gt;% filter(year &lt;= 2015) Before we interpolate, let’s look at two countries to get an idea of the data. p&lt;-gapminder_above60 %&gt;% filter(country==&quot;Albania&quot; | country==&quot;United States&quot;) %&gt;% ggplot(aes(x=year,y=above_60,color=country))+ geom_point() p We will use a spline to interpolate the data but we will first plot a linear interpolation to compare the the spline. temp1&lt;-data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;Albania&quot;),approx(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;Albania&quot;) temp2&lt;-data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;United States&quot;),approx(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;United States&quot;) p+ geom_line(data=temp1,mapping=aes(x=x,y=y)) + geom_line(data=temp2,mapping=aes(x=x,y=y)) + labs(x=&quot;Year&quot;,y=&quot;Percentage of Population above 60 years&quot;,title=&quot;Estimating Percent of Population Above 60&quot;,subtitle=&quot;Linear Interpolation&quot;) temp1&lt;-data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;Albania&quot;),spline(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;Albania&quot;) temp2&lt;-data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;United States&quot;),spline(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;United States&quot;) p+ geom_line(data=temp1,mapping=aes(x=x,y=y)) + geom_line(data=temp2,mapping=aes(x=x,y=y)) + labs(x=&quot;Year&quot;,y=&quot;Percentage of Population above 60 years&quot;,title=&quot;Estimating Percent of Population Above 60&quot;,subtitle=&quot;Spline Interpolation&quot;) Clean the work space. rm(temp1) rm(temp2) If you did not want the temporary variables we could have used the code in one step. p+ data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;Albania&quot;),spline(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;Albania&quot;) %&gt;% geom_line(mapping=aes(x=x,y=y)) + data.frame(with(gapminder_above60 %&gt;% filter(country==&quot;United States&quot;),spline(year,above_60,xout=seq(1950,2015)))) %&gt;% mutate(country=&quot;United States&quot;) %&gt;% geom_line(mapping=aes(x=x,y=y)) + labs(x=&quot;Year&quot;,y=&quot;Percentage of Population above 60 years&quot;, title=&quot;Estimating Percent of Population Above 60&quot;,subtitle=&quot;Spline Interpolation&quot;) Now we need to interpolate for every country and create our final data frame. We will use the map function from the purrr package. gapminder_above60&lt;-gapminder_above60 %&gt;% split(.$country) %&gt;% map(~data.frame(spline(.$year,.$above_60,xout=seq(1950,2015)))) %&gt;% map2_df(countries,~update_list(.x,country=.y)) %&gt;% mutate(year=as.integer(x),above_60=y) %&gt;% select(country,year,above_60) %&gt;% as.tibble() We finish by adding continent. gapminder_above60 &lt;- gapminder_above60 %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,above_60) %&gt;% arrange(year,country) gapminder_above60 %&gt;% head() %&gt;% knitr::kable() country continent year above_60 Afghanistan Asia 1950 4.503620 Albania Europe 1950 10.131796 Algeria Africa 1950 6.808316 Angola Africa 1950 4.944525 Argentina Americas 1950 7.043321 Australia Oceania 1950 12.458937 Finally, cleaning up the figure of our data. p+ geom_line(data=gapminder_above60%&gt;%filter(country==&quot;Albania&quot;),mapping=aes(x=year,y=above_60)) + geom_line(data=gapminder_above60%&gt;%filter(country==&quot;United States&quot;),mapping=aes(x=year,y=above_60)) + labs(x=&quot;Year&quot;,y=&quot;Percentage of Population above 60 years&quot;,title=&quot;Estimating Percent of Population Above 60&quot;,subtitle=&quot;Spline Interpolation&quot;) +theme_classic() 2.3.7 Final Data First we will do a quick quality check. table(gapminder_population$continent)/66 ## ## Africa Americas Asia Europe Oceania ## 52 25 33 30 2 table(gapminder_lifeexp$continent)/67 ## ## Africa Americas Asia Europe Oceania ## 52 25 33 30 2 table(gapminder_fertility$continent)/66 ## ## Africa Americas Asia Europe Oceania ## 52 25 33 30 2 table(gapminder_mortality5$continent)/66 ## ## Africa Americas Asia Europe Oceania ## 52 25 33 30 2 table(gapminder_above60$continent)/66 ## ## Africa Americas Asia Europe Oceania ## 50 23 31 29 2 table(dict$continent) ## ## Africa Americas Asia Europe Oceania ## 52 25 33 30 2 We have two problems left, the percentage of the population above 60 has less countries than the other data sets and life expectancy has one more year, 2016, than the other data sets. We will resolve this problem by dropping the 7 countries and the year 2016. gapminder_population %&gt;% summarise(Total=n_distinct(country)) ## # A tibble: 1 x 1 ## Total ## &lt;int&gt; ## 1 142 gapminder_above60 %&gt;% summarise(Total=n_distinct(country)) ## # A tibble: 1 x 1 ## Total ## &lt;int&gt; ## 1 135 unique(gapminder_population$country)[!unique(gapminder_population$country) %in% countries] ## [1] &quot;Central African Republic&quot; &quot;Czech Republic&quot; ## [3] &quot;Dominican Republic&quot; &quot;Hong Kong, China&quot; ## [5] &quot;Puerto Rico&quot; &quot;Reunion&quot; ## [7] &quot;Taiwan&quot; We drop by using the join function. gapminder_va&lt;-gapminder_above60 %&gt;% left_join(gapminder_lifeexp,by=c(&quot;country&quot;,&quot;year&quot;,&quot;continent&quot;)) %&gt;% left_join(gapminder_fertility,by=c(&quot;country&quot;,&quot;year&quot;,&quot;continent&quot;)) %&gt;% left_join(gapminder_population,by=c(&quot;country&quot;,&quot;year&quot;,&quot;continent&quot;)) %&gt;% left_join(gapminder_mortality5,by=c(&quot;country&quot;,&quot;year&quot;,&quot;continent&quot;)) %&gt;% arrange(year,country) Let’s look at the data. gapminder_va %&gt;% head() %&gt;% knitr::kable() country continent year above_60 life_exp fertility pop mortality Afghanistan Asia 1950 4.503620 26.85 7.67 7752118 439.56 Albania Europe 1950 10.131796 54.48 5.80 1263171 165.17 Algeria Africa 1950 6.808316 42.77 7.65 8872247 292.13 Angola Africa 1950 4.944525 30.70 6.93 4354882 404.92 Argentina Americas 1950 7.043321 61.61 3.16 17150335 93.53 Australia Oceania 1950 12.458937 69.01 3.07 8177344 31.60 One last note is that we have not included an economic metric such as gross domestic product, GDP, per capita. The reason is that the data is sparse. On the gapminder website the data starts in 1960 and ends in 2011; in addition many countries are missing data. On the World Bank site, the data is more complete but still has many missing values and goes from 1960 to 2016. The data in the gapminder package in R has data for each country but only in five year increments and ends in 2007. if you want to include GDP data you would have to make the choice of limiting the number of years, interpolating, and/or removing more countries. It would be too much to extrapolate from 2007 to 2015, so a possible solution is to merge the World Bank data with the data from the gapminder package. However, they are inflation adjusted on different times so a correction would have to be made. The World Bank data was in current US dollars while the gapminder package used something earlier, maybe 2000. Here is some code to investigate how to incorporate GDP, but we will not complete it for our work. It is only a start to give you an idea of the work involved. gapminder_gdp_temp &lt;- read_excel(&quot;data/World Bank GDP.xlsx&quot;,skip=4) gapminder_gdp&lt;-gapminder_gdp_temp %&gt;% gather(year,gdpPercap,-(&quot;Country Name&quot;:&quot;Indicator Code&quot;)) %&gt;% select(-(`Country Code`:`Indicator Code`)) %&gt;% rename(country=&quot;Country Name&quot;) %&gt;% mutate(year=as.integer(year)) We have a problem with the names of the countries again. gdp_countries&lt;-unique(gapminder_gdp$country) countries[!countries %in% gdp_countries] ## [1] &quot;Egypt&quot; &quot;Gambia&quot; &quot;Iran&quot; ## [4] &quot;Korea, Dem. Rep.&quot; &quot;Syria&quot; &quot;Venezuela&quot; There is a problem, we will determine if these countries are in the new data set and then correct the names. ind&lt;-vector() for (country in countries[!countries %in% gdp_countries]){ ind&lt;-c(ind,grep(substr(country,1,6),gdp_countries)) } gdp_countries[ind] ## [1] &quot;Egypt, Arab Rep.&quot; &quot;Gambia, The&quot; ## [3] &quot;Iran, Islamic Rep.&quot; &quot;Korea, Rep.&quot; ## [5] &quot;Korea, Dem. People’s Rep.&quot; &quot;Syrian Arab Republic&quot; ## [7] &quot;Venezuela, RB&quot; Let’s fix the names. We know Korea, Rep. is correct, let’s remove it. ind&lt;-ind[-4] #Two vectors of names to run a loop over old_names&lt;-gdp_countries[ind] new_names&lt;-countries[!countries %in% gdp_countries] for (i in seq_along(new_names)){ gapminder_gdp$country&lt;-gsub(old_names[i],new_names[i],gapminder_gdp$country) } gapminder_gdp&lt;-gapminder_gdp %&gt;% filter(country %in% countries,year&gt;=1992,year&lt;2017) %&gt;% arrange(country,year) Add continents to the data set. gapminder_gdp &lt;- gapminder_gdp %&gt;% left_join(dict,by=&quot;country&quot;) %&gt;% select(country,continent,year,gdpPercap) %&gt;% arrange(year,country) Now let’s get the data from the gapminder package and compare the years to determine how to adjust. head(gapminder_gdp %&gt;% filter(year == 2007) %&gt;% select(gdpPercap)/ gapminder %&gt;% filter(year == 2007,country %in% countries) %&gt;% select(gdpPercap) - (gapminder_gdp %&gt;% filter(year == 2002) %&gt;% select(gdpPercap)/ gapminder %&gt;% filter(year == 2002,country %in% countries) %&gt;% select(gdpPercap))) ## gdpPercap ## 1 0.1210036 ## 2 0.2911512 ## 3 0.2968434 ## 4 0.3436639 ## 5 0.2697395 ## 6 0.5360116 The adjustment is not consistent so we may be lacking some understanding of how inflation adjustment is being done. We will stop here but if you wanted to continue, you would adjust the data from the World Bank to be consistent with the gapminder data and then use interpolation similar to what was done with percentage of population above 60. We want to clean our work space. rm(gapminder_gdp_temp) rm(new_names) rm(old_names) Finally, we will write the data to a csv for use as needed for instruction. write.csv(gapminder_va,file=&quot;data/Gapminder_final.csv&quot;) 2.3.8 Summary of Data Collection To recap our data collection process, we will explain each variable. We have 135 countries on 5 continents for the years 1950 through and including 2015. Table 2.4 Table 2.4: The First Rows of our Final Data Set country continent year above_60 life_exp fertility pop mortality Afghanistan Asia 1950 4.503620 26.85 7.67 7752118 439.56 Albania Europe 1950 10.131796 54.48 5.80 1263171 165.17 Algeria Africa 1950 6.808316 42.77 7.65 8872247 292.13 Angola Africa 1950 4.944525 30.70 6.93 4354882 404.92 Argentina Americas 1950 7.043321 61.61 3.16 17150335 93.53 Australia Oceania 1950 12.458937 69.01 3.07 8177344 31.60 "],
["visualization-of-data.html", "2.4 Visualization of Data", " 2.4 Visualization of Data "],
["Chpt3.html", "Chapter 3 Inference in Visual Analytics", " Chapter 3 Inference in Visual Analytics We describe our methods in this chapter. "],
["Chpt4.html", "Chapter 4 Interactions", " Chapter 4 Interactions “It isn’t accidental that when we begin to understand something we say ‘I see.’ Not ‘I hear’ or ‘I smell’” – Stephen Few “You see alot just by looking” – Yogi Berra Visualization can surprise but doesn’t scale well. Modeling scales well but cannot surprise you. – Hadley Wickham http://junkcharts.typepad.com/junk_charts/junk-charts-trifecta-checkup-the-definitive-guide.html Use the unvotes package or NHANES data "],
["lesson-preparation-2.html", "4.1 Lesson Preparation", " 4.1 Lesson Preparation 4.1.1 Objectives: After the training, students will: explain the basic principles of visual displays of data be able to define visualization be able to use metrics to evaluate and compare visual displays of data be able 4.1.2 Preparation The following sites can be used as preparation material for this lesson, note they are arranged in a rough order of time commitment: 1) https://moz.com/blog/data-visualization-principles-lessons-from-tufte with a focus on the contents of good graphics. 2) https://www.columnfivemedia.com/makes-visualization-memorable this site offers some support of the previous link but also some counterpoints. See the paper at http://cvcl.mit.edu/papers/Borkin_etal_MemorableVisualization_TVCG2013.pdf for more details. 3) Read https://eagereyes.org/criticism/definition-of-visualization 4) Watch https://www.youtube.com/watch?v=AdSZJzb-aX8 The Art of Data Visualization 5) Watch https://www.youtube.com/watch?v=5Zg-C8AAIGg The Beauty of Data Visualization 6) Bring Data Viz into Class on Lesson One https://escholarship.org/uc/item/84v3774z For more detailed lesson or more experienced students: https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen?language=en Read Visualizing Categorical Data https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=6&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiwyPnessrUAhUL5WMKHaFhAioQFghSMAU&amp;url=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D517003&amp;usg=AFQjCNGvmx1AHiGmRZ5vHn7IPJWdStlZaQ&amp;sig2=G5Dly2rSS7I0v64zpo2T1Q Watch https://www.youtube.com/watch?v=R-oiKt7bUU8 Designing Data Visualizations with Noah Iliinsky Advances in Visualizing Categorical Data https://www.youtube.com/watch?v=qfNsoc7Tf60 Read http://neomam.com/interactive/13reasons/ Watch https://www.youtube.com/watch?v=8tJ4nBIU3q0 From the cognitive class on IBM Dark Horse Analytics three key points Less is more effective, less is more attractive, less is more impactful. They use a 3D pie as an example. https://courses.cognitiveclass.ai/courses/course-v1:CognitiveClass+DV0101EN+v1/courseware/407a9f86565c44189740699636b4fb85/12eab34ec218468995e4d06566ef4a32/ Also check out www.darkhorseanalytics.com In training session: Discuss the following: Definition from the above reading: Based on (non-visual) data. A visualization’s purpose is the communication of data. That means that the data must come from something that is abstract or at least not immediately visible (like the inside of the human body). This rules out photography and image processing. Visualization transforms from the invisible to the visible. Produce an image. It may seem obvious that a visualization has to produce an image, but that is not always so clear. Also, the visual must be the primary means of communication, other modalities can only provide additional information. If the image is only a small part of the process, it is not visualization. The result must be readable and recognizable. The most important criteria is that the visualization must provide a way to learn something about the data. Any transformation of non-trivial data into an image will leave out information, but there must be at least some relevant aspects of the data that can be read. The visualization must also be recognizable as one and not pretend to be something else (see the discussion of Informative Art). There are four important ingredients for information visualization: library(dplyr) library(htmlwidgets) library(rpivotTable) library(crosstalk) library(DT) library(leaflet) library(plotly) DT::datatable(iris) library(ggplot2) library(plotly) p &lt;- ggplot(data = diamonds, aes(x = cut, fill = clarity)) + geom_bar(position = &quot;dodge&quot;) ggplotly(p) ## We recommend that you use the dev version of ggplot2 with `ggplotly()` ## Install it with: `devtools::install_github(&#39;hadley/ggplot2&#39;)` data(mtcars) rpivotTable(mtcars,rows=&quot;gear&quot;, cols=c(&quot;cyl&quot;,&quot;carb&quot;),width=&quot;100%&quot;) devtools::install_github(&quot;jcheng5/d3scatter&quot;) library(htmlwidgets) library(crosstalk) library(leaflet) library(DT) library(d3scatter) shared_mtcars &lt;- SharedData$new(mtcars) bscols(widths = c(3,NA,NA), list( filter_checkbox(&quot;cyl&quot;, &quot;Cylinders&quot;, shared_mtcars, ~cyl, inline = TRUE), filter_slider(&quot;hp&quot;, &quot;Horsepower&quot;, shared_mtcars, ~hp, width = &quot;100%&quot;), filter_select(&quot;auto&quot;, &quot;Automatic&quot;, shared_mtcars, ~ifelse(am == 0, &quot;Yes&quot;, &quot;No&quot;)) ), d3scatter(shared_mtcars, ~wt, ~mpg, ~factor(cyl), width=&quot;100%&quot;, height=250), d3scatter(shared_mtcars, ~hp, ~qsec, ~factor(cyl), width=&quot;100%&quot;, height=250) ) Cylinders 4 6 8 Horsepower Automatic plot_ly(z = ~volcano) ## No trace type specified: ## Based on info supplied, a &#39;heatmap&#39; trace seems appropriate. ## Read more about this trace type -&gt; https://plot.ly/r/reference/#heatmap "],
["case-study.html", "Chapter 5 Case Study", " Chapter 5 Case Study Kiel’s Case Study Objectives: Students will: Appreciate the need for analytic reasoning related to data transformation Consider principles of visualization Explore the value of interactive visualizations Aircraft allocation across battlespace to provide adequate close air support coverage Background You just arrived at your new deployed job in the Strategy Division Operations Assessment Team at the Combined Air Operation Center (CAOC). The Operations Group mission planners have contacted your shop with a question about whether or not additional Close Air Support (CAS) F15E aircraft are needed, and if so, how many and at which airfield(s) they should be bedded to support which region(s) in Afghanistan. Additional questions were raised concerning your team’s recommendation for how many F-15E aircraft should be dedicated to each of the five regions of the country along with a recommended flying schedule for each region based on recent data. At the moment a fighter squadron is bedded at Airfield 1 and supports Region 1 and Region 4 using 16 F-15E aircraft. Another fighter squadron is bedded at the Airfield 2 and supports Regions 2, 3, and 5 using 24 F-15E aircraft. Each F-15E sortie departs and returns at the same time each day and consists of two F-15E aircraft providing six hours of CAS support. Additionally, each of the five regions must have 24/7 CAS coverage and each F-15E sortie can only cover one region during a single mission. Sustained 24/7 coverage over a region can therefore be provided by 8 F-15E aircraft as long as the alert aircraft (those scheduled to depart for the next sortie) are not called into action supporting the current sortie more than 25% of the time. Air refueling requirements are being handled by another member of your team and are not to be considered for the purposes of this analysis. Close Air Support (CAS) in Afghanistan largely centers on supporting Troops in Contact (TIC) events. Whenever ground forces are attacked and want air support, they declare a TIC and aircraft are dispatched to support them. For the purposes of this analysis assume each TIC is supported by a sortie of two F-15Es. Due to transit time within a region, no more than two simultaneous TICs per can be reasonably handled by an F-15E sortie, and every TIC needs to be supported by F-15E aircraft either already airborne within each region or by the two (or more) F-15E aircraft sitting alert. Airborne Warning and Control System (AWACS) serves to help coordinate CAS support to all TICs, especially those TICs that go “kinetic” (when supporting aircraft drop ordinance on targets). Your boss needs to make a recommendation as to whether more air assets are needed for current operations. We start with 200 recent close air support (CAS) events. Each row of data represents a TIC event with a date, start/stop time, location (region), and whether munitions were employed. Using this data, how do you present analysis regarding the deployment of air assets to cover close air support? "],
["AppA.html", "A Lesson Handouts", " A Lesson Handouts "],
["AppB.html", "B Project", " B Project B.0.1 Introduction "],
["references.html", "References", " References "]
]
